{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-31T16:48:50.080821Z",
     "start_time": "2025-03-31T16:48:48.005034Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "device(type='mps')"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Set device: use MPS if available on MacBook Pro, else CUDA, else CPU.\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    \n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------------\n",
    "# 1. Contrastive Dataset Definition\n",
    "# ---------------------------\n",
    "class ContrastiveProductDataset(Dataset):\n",
    "    def __init__(self, csv_file):\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        required_cols = ['asin', 'cleaned_review', 'cleaned_metadata', 'rating', 'price']\n",
    "        for col in required_cols:\n",
    "            if col not in self.df.columns:\n",
    "                raise ValueError(f\"CSV file is missing required column: {col}\")\n",
    "        # Shuffle the data initially\n",
    "        self.df = self.df.sample(frac=1).reset_index(drop=True)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        # View 1: cleaned review text (user perspective)\n",
    "        view1 = str(row['cleaned_review']).strip()\n",
    "        # View 2: combine metadata with price and rating (product details)\n",
    "        view2 = f\"{str(row['cleaned_metadata']).strip()}. Price: {row['price']}. Rating: {row['rating']}.\"\n",
    "        return {\"view1\": view1, \"view2\": view2}\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-31T16:48:50.894496Z",
     "start_time": "2025-03-31T16:48:50.886453Z"
    }
   },
   "id": "9dbc12a907afa509"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "def my_collate_fn(batch, tokenizer, max_length=128):\n",
    "    view1_texts = [item[\"view1\"] for item in batch]\n",
    "    view2_texts = [item[\"view2\"] for item in batch]\n",
    "    \n",
    "    encoded_view1 = tokenizer(\n",
    "        view1_texts,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    encoded_view2 = tokenizer(\n",
    "        view2_texts,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    return {\n",
    "        \"view1_input_ids\": encoded_view1[\"input_ids\"],\n",
    "        \"view1_attention_mask\": encoded_view1[\"attention_mask\"],\n",
    "        \"view2_input_ids\": encoded_view2[\"input_ids\"],\n",
    "        \"view2_attention_mask\": encoded_view2[\"attention_mask\"],\n",
    "    }"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-31T16:48:51.505719Z",
     "start_time": "2025-03-31T16:48:51.503826Z"
    }
   },
   "id": "3ecd2c6e7386adaa"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------------\n",
    "# 2. Model Architecture: Dual Encoder with SBERT\n",
    "# ---------------------------\n",
    "class DualEncoderSBERT(nn.Module):\n",
    "    def __init__(self, model_name=\"sentence-transformers/all-MiniLM-L12-v2\", embed_dim=128):\n",
    "        \"\"\"\n",
    "        Uses SBERT as a base model. The chosen model outputs 384-dimensional embeddings.\n",
    "        We then add a projection head mapping to a lower-dimensional space (e.g., 128 dims).\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        # Load SBERT-style model\n",
    "        self.encoder = AutoModel.from_pretrained(model_name)\n",
    "        \n",
    "        # Projection head: maps from 384 (MiniLM) to embed_dim.\n",
    "        self.projection = nn.Sequential(\n",
    "            nn.Linear(self.encoder.config.hidden_size, embed_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(embed_dim, embed_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        # Use the first token's embedding as the sentence representation (like [CLS])\n",
    "        cls_emb = outputs.last_hidden_state[:, 0]  # shape: (batch, hidden_size)\n",
    "        proj = self.projection(cls_emb)\n",
    "        # Normalize embeddings for cosine similarity\n",
    "        return F.normalize(proj, p=2, dim=1)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-31T16:48:51.953829Z",
     "start_time": "2025-03-31T16:48:51.948419Z"
    }
   },
   "id": "60479a9423ea0d9f"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------------\n",
    "# 3. Contrastive Loss (InfoNCE)\n",
    "# ---------------------------\n",
    "def info_nce_loss(embeddings1, embeddings2, temperature=0.07):\n",
    "    \"\"\"\n",
    "    Computes InfoNCE loss between two sets of embeddings.\n",
    "    For each sample, the positive pair is at the same index,\n",
    "    while other samples in the batch are treated as negatives.\n",
    "    \"\"\"\n",
    "    logits = torch.mm(embeddings1, embeddings2.t()) / temperature\n",
    "    labels = torch.arange(logits.shape[0]).to(logits.device)\n",
    "    loss = F.cross_entropy(logits, labels)\n",
    "    return loss\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-31T16:48:52.324169Z",
     "start_time": "2025-03-31T16:48:52.322415Z"
    }
   },
   "id": "5ff022e678360b10"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "def evaluate_model(model_view1, model_view2, dataloader, temperature=0.07):\n",
    "    \"\"\"\n",
    "    Computes retrieval metrics on the validation set.\n",
    "    We'll compute Recall@1 and Mean Reciprocal Rank (MRR).\n",
    "    The assumption is that for each sample, the correct pair is on the diagonal.\n",
    "    \"\"\"\n",
    "    model_view1.eval()\n",
    "    model_view2.eval()\n",
    "    \n",
    "    all_emb_view1 = []\n",
    "    all_emb_view2 = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            view1_ids = batch[\"view1_input_ids\"].to(device)\n",
    "            view1_mask = batch[\"view1_attention_mask\"].to(device)\n",
    "            view2_ids = batch[\"view2_input_ids\"].to(device)\n",
    "            view2_mask = batch[\"view2_attention_mask\"].to(device)\n",
    "            \n",
    "            emb1 = model_view1(view1_ids, view1_mask)\n",
    "            emb2 = model_view2(view2_ids, view2_mask)\n",
    "            \n",
    "            all_emb_view1.append(emb1.cpu())\n",
    "            all_emb_view2.append(emb2.cpu())\n",
    "    \n",
    "    all_emb_view1 = torch.cat(all_emb_view1, dim=0)\n",
    "    all_emb_view2 = torch.cat(all_emb_view2, dim=0)\n",
    "    \n",
    "    # Compute similarity matrix\n",
    "    sims = torch.mm(all_emb_view1, all_emb_view2.t())\n",
    "    sims_np = sims.numpy()\n",
    "    \n",
    "    # For each query (row), compute the rank of the correct pair (diagonal element)\n",
    "    ranks = []\n",
    "    for i in range(sims_np.shape[0]):\n",
    "        # Sort indices in descending order of similarity\n",
    "        sorted_indices = np.argsort(-sims_np[i])\n",
    "        # Find rank of the i-th sample (correct pairing)\n",
    "        rank = np.where(sorted_indices == i)[0][0] + 1  # ranks start at 1\n",
    "        ranks.append(rank)\n",
    "    \n",
    "    ranks = np.array(ranks)\n",
    "    recall_at_1 = np.mean(ranks == 1)\n",
    "    mrr = np.mean(1.0 / ranks)\n",
    "    \n",
    "    return recall_at_1, mrr"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-31T16:48:52.830420Z",
     "start_time": "2025-03-31T16:48:52.825633Z"
    }
   },
   "id": "56df80007841ec51"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from torch.optim import AdamW\n",
    "\n",
    "\n",
    "def train_and_evaluate(train_csv, val_csv, epochs=3, batch_size=32, lr=2e-5,\n",
    "                       temperature=0.07, max_length=128, num_workers=4):\n",
    "    # Create datasets and dataloaders for train and validation splits.\n",
    "    train_dataset = ContrastiveProductDataset(train_csv)\n",
    "    val_dataset = ContrastiveProductDataset(val_csv)\n",
    "    \n",
    "    # Initialize tokenizer for collate function.\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L12-v2\")\n",
    "    \n",
    "    collate = partial(my_collate_fn, tokenizer=tokenizer, max_length=max_length)\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        collate_fn=collate\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        collate_fn=collate\n",
    "    )\n",
    "    \n",
    "    # Initialize two models for the two views.\n",
    "    model_view1 = DualEncoderSBERT(model_name=\"sentence-transformers/all-MiniLM-L12-v2\").to(device)\n",
    "    model_view2 = DualEncoderSBERT(model_name=\"sentence-transformers/all-MiniLM-L12-v2\").to(device)\n",
    "    \n",
    "    optimizer = AdamW(list(model_view1.parameters()) + list(model_view2.parameters()), lr=lr)\n",
    "    \n",
    "    best_recall = 0.0\n",
    "    best_epoch = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model_view1.train()\n",
    "        model_view2.train()\n",
    "        total_loss = 0.0\n",
    "        \n",
    "        for batch in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}/{epochs}\"):\n",
    "            view1_ids = batch[\"view1_input_ids\"].to(device)\n",
    "            view1_mask = batch[\"view1_attention_mask\"].to(device)\n",
    "            view2_ids = batch[\"view2_input_ids\"].to(device)\n",
    "            view2_mask = batch[\"view2_attention_mask\"].to(device)\n",
    "            \n",
    "            emb1 = model_view1(view1_ids, view1_mask)\n",
    "            emb2 = model_view2(view2_ids, view2_mask)\n",
    "            \n",
    "            loss = info_nce_loss(emb1, emb2, temperature)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch+1} - Training Loss: {avg_loss:.4f}\")\n",
    "        \n",
    "        # Evaluate on validation set after each epoch\n",
    "        recall_at_1, mrr = evaluate_model(model_view1, model_view2, val_loader, temperature)\n",
    "        print(f\"Epoch {epoch+1} - Validation Recall@1: {recall_at_1:.4f}, MRR: {mrr:.4f}\")\n",
    "        \n",
    "        # Save best model based on Recall@1\n",
    "        if recall_at_1 > best_recall:\n",
    "            best_recall = recall_at_1\n",
    "            best_epoch = epoch + 1\n",
    "            torch.save(model_view1.state_dict(), \"best_model_view1.pt\")\n",
    "            torch.save(model_view2.state_dict(), \"best_model_view2.pt\")\n",
    "            print(f\"New best model found at epoch {epoch+1} with Recall@1: {best_recall:.4f}\")\n",
    "    \n",
    "    print(f\"Training complete. Best model at epoch {best_epoch} with Recall@1: {best_recall:.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-31T16:48:53.365379Z",
     "start_time": "2025-03-31T16:48:53.362213Z"
    }
   },
   "id": "8e0b8c795e93a48d"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-31T16:48:53.864725Z",
     "start_time": "2025-03-31T16:48:53.862472Z"
    }
   },
   "id": "eab86f94ed183017"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def test_evaluate(test_csv, max_length=128, batch_size=32, num_workers=4):\n",
    "    # Load test dataset\n",
    "    test_dataset = ContrastiveProductDataset(test_csv)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L12-v2\")\n",
    "    collate = partial(my_collate_fn, tokenizer=tokenizer, max_length=max_length)\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        collate_fn=collate\n",
    "    )\n",
    "    \n",
    "    # Load the best models saved from training.\n",
    "    model_view1 = DualEncoderSBERT(model_name=\"sentence-transformers/all-MiniLM-L12-v2\").to(device)\n",
    "    model_view2 = DualEncoderSBERT(model_name=\"sentence-transformers/all-MiniLM-L12-v2\").to(device)\n",
    "    model_view1.load_state_dict(torch.load(\"best_model_view1.pt\", map_location=device))\n",
    "    model_view2.load_state_dict(torch.load(\"best_model_view2.pt\", map_location=device))\n",
    "    \n",
    "    recall_at_1, mrr = evaluate_model(model_view1, model_view2, test_loader)\n",
    "    print(f\"Test Evaluation - Recall@1: {recall_at_1:.4f}, MRR: {mrr:.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-31T16:48:54.245319Z",
     "start_time": "2025-03-31T16:48:54.238775Z"
    }
   },
   "id": "c29b053c4d36c95a"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "train_csv='/Users/sanamoin/Documents/sites/gadgets/recommendation_engine/data/filtered_splits/electronics_train.csv'\n",
    "val_csv='/Users/sanamoin/Documents/sites/gadgets/recommendation_engine/data/filtered_splits/electronics_val.csv'\n",
    "test_csv='/Users/sanamoin/Documents/sites/gadgets/recommendation_engine/data/filtered_splits/electronics_test.csv'\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-31T16:48:54.868105Z",
     "start_time": "2025-03-31T16:48:54.866007Z"
    }
   },
   "id": "b6db787496bb9230"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/3:   0%|          | 0/62251 [00:00<?, ?it/s]Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/spawn.py\", line 122, in spawn_main\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/spawn.py\", line 132, in _main\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "AttributeError: Can't get attribute 'ContrastiveProductDataset' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\n",
      "Training Epoch 1/3:   0%|          | 0/62251 [00:23<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m freeze_support()\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# Train and evaluate on validation set.\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m \u001B[43mtrain_and_evaluate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_csv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_csv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m32\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2e-5\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m                   \u001B[49m\u001B[43mtemperature\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.07\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmax_length\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m128\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_workers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[7], line 46\u001B[0m, in \u001B[0;36mtrain_and_evaluate\u001B[0;34m(train_csv, val_csv, epochs, batch_size, lr, temperature, max_length, num_workers)\u001B[0m\n\u001B[1;32m     43\u001B[0m model_view2\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[1;32m     44\u001B[0m total_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0.0\u001B[39m\n\u001B[0;32m---> 46\u001B[0m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtqdm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdesc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43mf\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mTraining Epoch \u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mepoch\u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m/\u001B[39;49m\u001B[38;5;132;43;01m{\u001B[39;49;00m\u001B[43mepochs\u001B[49m\u001B[38;5;132;43;01m}\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m     47\u001B[0m \u001B[43m    \u001B[49m\u001B[43mview1_ids\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mview1_input_ids\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     48\u001B[0m \u001B[43m    \u001B[49m\u001B[43mview1_mask\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mview1_attention_mask\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/sites/gadgets/backend/venv/lib/python3.12/site-packages/tqdm/std.py:1181\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1178\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[1;32m   1180\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1181\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43miterable\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m   1182\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01myield\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\n\u001B[1;32m   1183\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Update and possibly print the progressbar.\u001B[39;49;00m\n\u001B[1;32m   1184\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;49;00m\n",
      "File \u001B[0;32m~/Documents/sites/gadgets/backend/venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:491\u001B[0m, in \u001B[0;36mDataLoader.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    489\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterator\n\u001B[1;32m    490\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 491\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/sites/gadgets/backend/venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:422\u001B[0m, in \u001B[0;36mDataLoader._get_iterator\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    420\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    421\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_worker_number_rationality()\n\u001B[0;32m--> 422\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_MultiProcessingDataLoaderIter\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Documents/sites/gadgets/backend/venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1146\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter.__init__\u001B[0;34m(self, loader)\u001B[0m\n\u001B[1;32m   1139\u001B[0m w\u001B[38;5;241m.\u001B[39mdaemon \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m   1140\u001B[0m \u001B[38;5;66;03m# NB: Process.start() actually take some time as it needs to\u001B[39;00m\n\u001B[1;32m   1141\u001B[0m \u001B[38;5;66;03m#     start a process and pass the arguments over via a pipe.\u001B[39;00m\n\u001B[1;32m   1142\u001B[0m \u001B[38;5;66;03m#     Therefore, we only add a worker to self._workers list after\u001B[39;00m\n\u001B[1;32m   1143\u001B[0m \u001B[38;5;66;03m#     it started, so that we do not call .join() if program dies\u001B[39;00m\n\u001B[1;32m   1144\u001B[0m \u001B[38;5;66;03m#     before it starts, and __del__ tries to join but will get:\u001B[39;00m\n\u001B[1;32m   1145\u001B[0m \u001B[38;5;66;03m#     AssertionError: can only join a started process.\u001B[39;00m\n\u001B[0;32m-> 1146\u001B[0m \u001B[43mw\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstart\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1147\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_index_queues\u001B[38;5;241m.\u001B[39mappend(index_queue)\n\u001B[1;32m   1148\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_workers\u001B[38;5;241m.\u001B[39mappend(w)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/process.py:121\u001B[0m, in \u001B[0;36mBaseProcess.start\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    118\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _current_process\u001B[38;5;241m.\u001B[39m_config\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdaemon\u001B[39m\u001B[38;5;124m'\u001B[39m), \\\n\u001B[1;32m    119\u001B[0m        \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdaemonic processes are not allowed to have children\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    120\u001B[0m _cleanup()\n\u001B[0;32m--> 121\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_popen \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_Popen\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    122\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sentinel \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_popen\u001B[38;5;241m.\u001B[39msentinel\n\u001B[1;32m    123\u001B[0m \u001B[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001B[39;00m\n\u001B[1;32m    124\u001B[0m \u001B[38;5;66;03m# reference to the process object (see bpo-30775)\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/context.py:224\u001B[0m, in \u001B[0;36mProcess._Popen\u001B[0;34m(process_obj)\u001B[0m\n\u001B[1;32m    222\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[1;32m    223\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_Popen\u001B[39m(process_obj):\n\u001B[0;32m--> 224\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_default_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_context\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mProcess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_Popen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/context.py:289\u001B[0m, in \u001B[0;36mSpawnProcess._Popen\u001B[0;34m(process_obj)\u001B[0m\n\u001B[1;32m    286\u001B[0m \u001B[38;5;129m@staticmethod\u001B[39m\n\u001B[1;32m    287\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m_Popen\u001B[39m(process_obj):\n\u001B[1;32m    288\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpopen_spawn_posix\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Popen\n\u001B[0;32m--> 289\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mPopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/popen_spawn_posix.py:32\u001B[0m, in \u001B[0;36mPopen.__init__\u001B[0;34m(self, process_obj)\u001B[0m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, process_obj):\n\u001B[1;32m     31\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fds \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m---> 32\u001B[0m     \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/popen_fork.py:19\u001B[0m, in \u001B[0;36mPopen.__init__\u001B[0;34m(self, process_obj)\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturncode \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfinalizer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m---> 19\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_launch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocess_obj\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/multiprocessing/popen_spawn_posix.py:62\u001B[0m, in \u001B[0;36mPopen._launch\u001B[0;34m(self, process_obj)\u001B[0m\n\u001B[1;32m     60\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msentinel \u001B[38;5;241m=\u001B[39m parent_r\n\u001B[1;32m     61\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(parent_w, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mwb\u001B[39m\u001B[38;5;124m'\u001B[39m, closefd\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m---> 62\u001B[0m         \u001B[43mf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwrite\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetbuffer\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[1;32m     64\u001B[0m     fds_to_close \u001B[38;5;241m=\u001B[39m []\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from multiprocessing import freeze_support\n",
    "\n",
    "freeze_support()\n",
    "# Train and evaluate on validation set.\n",
    "train_and_evaluate(train_csv, val_csv, epochs=3, batch_size=32, lr=2e-5,\n",
    "                   temperature=0.07, max_length=128, num_workers=4)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-03-31T16:51:28.173833Z",
     "start_time": "2025-03-31T16:50:42.558248Z"
    }
   },
   "id": "9554e1f07793fbdd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Finally, evaluate on the test set using the best saved model.\n",
    "test_evaluate(test_csv, max_length=128, batch_size=32, num_workers=4)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e8fb3e1377fe960a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d2fdad966b5328e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ea7e454e9da28b9a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
